{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/desstaw/DataPrivacy_SimulatedAnnealing/blob/main/DemoApp_SA_MIMICIII_Adult.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjPgvvM1j_Tw"
      },
      "source": [
        "## Import the data and briefly explore it again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6tkNiX_9MXw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf6F7t-opUto"
      },
      "source": [
        "### Streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J4scQKwsZOT",
        "outputId": "33f78931-fbf3-4e03-a408-c942cd7170e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "import random\n",
        "import math\n",
        "import streamlit as st\n",
        "import random\n",
        "import math\n",
        "\n",
        "# Add your existing code here\n",
        "url = \"https://raw.githubusercontent.com/desstaw/PrivacyPreservingTechniques/main/SA%20Demo%20App/pre-processed-MIMICIII-SA(arx_gen).csv\"\n",
        "df_org_mimic = pd.read_csv(url)\n",
        "\n",
        "url1 = \"https://raw.githubusercontent.com/desstaw/PrivacyPreservingTechniques/main/SA%20Demo%20App/Experimental%20Outcome%20MIMIC%20III.csv\"\n",
        "df_exp_mimic = pd.read_csv(url1)\n",
        "\n",
        "df_res_init = df_org_mimic[['L6_age', 'L2_los_hours', 'L2_Admission_Type', 'L1_Diseases', 'L2_Ethnicity']].copy()\n",
        "df_org = df_org_mimic[['L7_age', 'L7_los_hours', 'L2_Admission_Type', 'L2_Diseases', 'L3_Ethnicity']].copy()\n",
        "\n",
        "url2 = \"https://raw.githubusercontent.com/desstaw/PrivacyPreservingTechniques/main/datasets/adult_v1_gen.csv\"\n",
        "df_org_adult = pd.read_csv(url2)\n",
        "\n",
        "url3 = \"https://raw.githubusercontent.com/desstaw/PrivacyPreservingTechniques/main/SA%20Demo%20App/Experimental%20Outcome%20Adult.csv\"\n",
        "df_exp_adult = pd.read_csv(url3)\n",
        "\n",
        "df_res_init_adult = df_org_adult[['sex', 'L6_age', 'L2_race', 'L3_education', 'L3_occupation', 'L3_workclass', 'L2_marital_status', 'L1_native_country']].copy()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define function for the page overview of MIMIC III Dataset\n",
        "def mimic_dataset_overview():\n",
        "\n",
        "\n",
        "    def calculate_suppression_fraction(df, k, test_solution):\n",
        "        # Group the dataset by the quasi-identifiers\n",
        "        grouped = df.groupby(test_solution)\n",
        "        suppressed_indices = []\n",
        "\n",
        "        # Identify groups with less than k rows and mark for suppression\n",
        "        for group_name, group in grouped:\n",
        "            if len(group) < k:\n",
        "                suppressed_indices.extend(group.index)\n",
        "\n",
        "        # Drop suppressed rows\n",
        "        df_k = df.drop(suppressed_indices)\n",
        "\n",
        "        # Restore the original index\n",
        "        df_index = df_k.index\n",
        "        df_k = df_k.reset_index(drop=True)\n",
        "\n",
        "        # Calculate suppression fraction\n",
        "        suppressed_rows = len(suppressed_indices)\n",
        "        total_rows = len(df)\n",
        "        initial_suppression = suppressed_rows / total_rows\n",
        "        initial_suppression = round(initial_suppression * 100, 2)\n",
        "\n",
        "        return initial_suppression\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def get_accuracy(df1, k, max_suppressed_fraction): # Takes experimental results df as input and returns auroc, solution set and suppression %\n",
        "        # Filter DataFrame based on k and max_supp values\n",
        "        filtered_df = df1[(df1['K'] == k) & (df1['max suppression %'] == max_suppressed_fraction)]\n",
        "\n",
        "        # Check if any rows match the criteria\n",
        "        if not filtered_df.empty:\n",
        "            # Retrieve accuracy value (assuming there's only one match)\n",
        "            accuracy_value = filtered_df['median auroc'].iloc[0]\n",
        "            suprression_value = filtered_df['suppression in %'].iloc[0]\n",
        "            solution_set = filtered_df['solution set SA'].iloc[0]\n",
        "            solution_set = [item.strip(\"'\") for item in solution_set.split(\",\")]\n",
        "            # Clean up the solution set\n",
        "            solution_set = [col.strip().replace(\"'\", \"\").replace('\"', '') for col in solution_set]\n",
        "\n",
        "            return accuracy_value, suprression_value, solution_set\n",
        "        else:\n",
        "            return None  # Return None if no matching rows found\n",
        "\n",
        "    def display_datasets(df_res_init, df_org, subset_df):\n",
        "        st.header(\"Display Datasets\")\n",
        "        # Create columns to display datasets side by side\n",
        "        selected_datasets = st.multiselect(\"Select datasets to display:\", [\"Original Dataset\", \"Initial Dataset\", \"Optimized Dataset\"], default=[\"Original Dataset\"] )\n",
        "        # Calculate the number of columns needed based on the number of selected datasets\n",
        "        num_columns = len(selected_datasets)\n",
        "        # Create columns to display datasets side by side\n",
        "        cols = st.columns(num_columns)\n",
        "\n",
        "\n",
        "        for i, dataset in enumerate(selected_datasets):\n",
        "            if dataset == \"Original Dataset\":\n",
        "                with cols[i]:\n",
        "                    st.write(\"### Original Dataset\")\n",
        "                    st.dataframe(df_org)\n",
        "            elif dataset == \"Initial Dataset\":\n",
        "                with cols[i]:\n",
        "                    st.write(\"### Initial Dataset\")\n",
        "                    st.dataframe(df_res_init)\n",
        "            elif dataset == \"Optimized Dataset\":\n",
        "                with cols[i]:\n",
        "                    st.write(\"### Optimized Dataset\")\n",
        "                    st.dataframe(subset_df)\n",
        "\n",
        "\n",
        "\n",
        "    def display_datasets_with_distribution(original_dataset, anon_dataset):\n",
        "          st.subheader(\"Display change in data distribution after anonymization:\")\n",
        "          tab1, tab2, tab3, tab4, tab5 = st.tabs([\"Age\", \"Gender\", \"Ethnicity\", \"Diseases\", \"Death within 360 days\"])\n",
        "\n",
        "          with tab1:\n",
        "              # Filter columns containing the word \"age\"\n",
        "              age_column = [col for col in anon_dataset.columns if 'age' in col.lower()]\n",
        "              print(\"Age column?\", age_column)\n",
        "\n",
        "              fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "              sns.histplot(original_dataset[\"L7_age\"], kde=True, color=\"blue\", label=\"Original Dataset\", ax=axes[0])\n",
        "              axes[0].set_xlabel(\"Age\")\n",
        "              axes[0].set_ylabel(\"Frequency\")\n",
        "              axes[0].set_title(\"Distribution of Age (Original Dataset)\")\n",
        "\n",
        "              sns.histplot(anon_dataset[age_column[0]], kde=True, color=\"orange\", label=\"Anonymized Dataset\", ax=axes[1])\n",
        "              axes[1].set_xlabel(\"Age\")\n",
        "              axes[1].set_ylabel(\"Frequency\")\n",
        "              axes[1].set_title(\"Distribution of Age (Anonymized Dataset)\")\n",
        "              axes[1].tick_params(axis='x', labelrotation=90)\n",
        "\n",
        "              plt.tight_layout()\n",
        "              st.pyplot(fig)\n",
        "\n",
        "          with tab2:\n",
        "              # Filter columns containing the word \"gender\"\n",
        "              gender_column = [col for col in anon_dataset.columns if 'gender' in col.lower()]\n",
        "              #print(\"Age column?\", gender_column)\n",
        "\n",
        "              fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "              sns.histplot(original_dataset[\"gender\"], kde=True, color=\"blue\", label=\"Original Dataset\", ax=axes[0])\n",
        "              axes[0].set_xlabel(\"Gender\")\n",
        "              axes[0].set_ylabel(\"Frequency\")\n",
        "              axes[0].set_title(\"Distribution of gender (Original Dataset)\")\n",
        "\n",
        "              sns.histplot(anon_dataset[gender_column[0]], kde=True, color=\"orange\", label=\"Anonymized Dataset\", ax=axes[1])\n",
        "              axes[1].set_xlabel(\"Gender\")\n",
        "              axes[1].set_ylabel(\"Frequency\")\n",
        "              axes[1].set_title(\"Distribution of Gender (Anonymized Dataset)\")\n",
        "              axes[1].tick_params(axis='x', labelrotation=90)\n",
        "\n",
        "              plt.tight_layout()\n",
        "              st.pyplot(fig)\n",
        "\n",
        "          with tab3:\n",
        "              # Filter columns containing the word \"ethnicity\"\n",
        "              ethnicity_column = [col for col in anon_dataset.columns if 'ethnicity' in col.lower()]\n",
        "              #print(\"Age column?\", ethnicity_column)\n",
        "\n",
        "              fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "              sns.histplot(original_dataset[\"L3_Ethnicity\"], kde=True, color=\"blue\", label=\"Original Dataset\", ax=axes[0])\n",
        "              axes[0].set_xlabel(\"Ethnicity\")\n",
        "              axes[0].set_ylabel(\"Frequency\")\n",
        "              axes[0].set_title(\"Distribution of Ethnicity (Original Dataset)\")\n",
        "\n",
        "              sns.histplot(anon_dataset[ethnicity_column[0]], kde=True, color=\"orange\", label=\"Anonymized Dataset\", ax=axes[1])\n",
        "              axes[1].set_xlabel(\"L3_Ethnicity\")\n",
        "              axes[1].set_ylabel(\"Frequency\")\n",
        "              axes[1].set_title(\"Distribution of Ethnicity (Anonymized Dataset)\")\n",
        "              axes[1].tick_params(axis='x', labelrotation=90)\n",
        "\n",
        "              plt.tight_layout()\n",
        "              st.pyplot(fig)\n",
        "\n",
        "          with tab4:\n",
        "              # Filter columns containing the word \"diseases\"\n",
        "              diseases_column = [col for col in anon_dataset.columns if 'diseases' in col.lower()]\n",
        "              #print(\"Age column?\", diseases_column)\n",
        "\n",
        "              fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "              sns.histplot(original_dataset[\"diseases\"], kde=True, color=\"blue\", label=\"Original Dataset\", ax=axes[0])\n",
        "              axes[0].set_xlabel(\"Diseases\")\n",
        "              axes[0].set_ylabel(\"Frequency\")\n",
        "              axes[0].set_title(\"Distribution of Diseases (Original Dataset)\")\n",
        "\n",
        "              sns.histplot(anon_dataset[diseases_column[0]], kde=True, color=\"orange\", label=\"Anonymized Dataset\", ax=axes[1])\n",
        "              axes[1].set_xlabel(\"Diseases\")\n",
        "              axes[1].set_ylabel(\"Frequency\")\n",
        "              axes[1].set_title(\"Distribution of Diseases (Anonymized Dataset)\")\n",
        "              axes[1].tick_params(axis='x', labelrotation=90)\n",
        "\n",
        "              plt.tight_layout()\n",
        "              st.pyplot(fig)\n",
        "\n",
        "          with tab5:\n",
        "              # Filter columns containing the word \"death\"\n",
        "              death_column = [col for col in anon_dataset.columns if 'death' in col.lower()]\n",
        "\n",
        "              fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "              sns.histplot(original_dataset[\"death_365_days\"], kde=True, color=\"blue\", label=\"Original Dataset\", ax=axes[0])\n",
        "              axes[0].set_xlabel(\"Diseases\")\n",
        "              axes[0].set_ylabel(\"Frequency\")\n",
        "              axes[0].set_title(\"Distribution of Diseases (Original Dataset)\")\n",
        "\n",
        "              sns.histplot(anon_dataset[death_column[0]], kde=True, color=\"orange\", label=\"Anonymized Dataset\", ax=axes[1])\n",
        "              axes[1].set_xlabel(\"Death within 365 days\")\n",
        "              axes[1].set_ylabel(\"Frequency\")\n",
        "              axes[1].set_title(\"Distribution of Death within 365 days (Anonymized Dataset)\")\n",
        "              axes[1].tick_params(axis='x', labelrotation=90)\n",
        "\n",
        "              plt.tight_layout()\n",
        "              st.pyplot(fig)\n",
        "\n",
        "    # Define the Streamlit app title\n",
        "    st.header(\"Simulated Annealing Optimization - MIMIC III\")\n",
        "    st.markdown(\"MIMIC-III integrates deidentified, comprehensive clinical data of patients admitted to the Beth Israel Deaconess Medical Center in Boston, Massachusetts it is preprocessed to predict 365-day mortality probability among intensive care unit (ICU) stroke inpatients between 2001 and 2012.\")\n",
        "    #st.markdown(''' :red[Streamlit] :orange[can] :green[write] :blue[text] :violet[in] :gray[pretty] :rainbow[colors].''')\n",
        "    st.markdown(''':green[Predictors:] age, length of stay/h, admission type, gender, stroke type, marital status, diseases, ethnicity, infarct type, anion gap, abp diastolic, abp systolic, bicarbonate, calcium, chloride, creatinine, gcs, glucose, heart rate, hemoglobin,  oasis, wbc, platelet count, potassium, respiratory rate, sodium ''')\n",
        "    # Quasi Identifiers\n",
        "    #st.markdown(\"<span style='color:green'>**Quasi Identifiers:**</span>\", unsafe_allow_html=True)\n",
        "    st.markdown( ''':green[Quasi identifiers:] age, length of stay/h, admission type, gender, stroke type, marital status, diseases, ethnicity ''')\n",
        "\n",
        "    ##################################################--------------------SIDEBAR-------------------#######################################\n",
        "    # Create Streamlit widgets for user input\n",
        "    st.sidebar.header(\"User Settings\")\n",
        "    k = st.sidebar.slider(\"k-Anonymity Threshold\", min_value=2, max_value=10, value=2, step=1)\n",
        "\n",
        "    max_suppressed_fraction = st.sidebar.slider(\"Maximum suppression\", min_value=10, max_value=30, value=20, step=10)\n",
        "\n",
        "    accuracy_value, suprression_value, solution_set = get_accuracy(df_exp_mimic, k, max_suppressed_fraction)\n",
        "\n",
        "    initial_solution = ['L6_age', 'L2_los_hours', 'L2_Admission_Type', 'gender', 'stroke_type', 'marital_status', 'L1_Diseases', 'L2_Ethnicity']\n",
        "    #k_init = st.sidebar.slider(\"k-Anonymity on initial solution\", min_value=2, max_value=10, value=2, step=1)\n",
        "    initial_suppression = calculate_suppression_fraction(df_org_mimic, k, initial_solution) # change to percentage to have suppression percentage of initial random solution when k is applied\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ##################################################--------------------Privacy Indicator (Ampel)-------------------#######################################\n",
        "    def categorize_solution(solution_set):\n",
        "        # Extract numbers from column names\n",
        "        numbers = [int(''.join(filter(str.isdigit, col))) for col in solution_set if any(char.isdigit() for char in col)]\n",
        "\n",
        "        # Sum up the numbers\n",
        "        total = sum(numbers)\n",
        "\n",
        "        # Normalize the score\n",
        "        #normalized_score = (total - min(numbers)) / (max(numbers) - min(numbers))\n",
        "\n",
        "       # Reverse the score\n",
        "        #reversed_score = 1 - normalized_score\n",
        "\n",
        "      # Categorize based on the reversed normalized score\n",
        "        if 5 <= total <= 10:\n",
        "            return total\n",
        "        elif 11 <= total <= 15:\n",
        "            return total\n",
        "        else:\n",
        "            return total\n",
        "\n",
        "    # Example usage:\n",
        "    #solution_set = ['L1_age', 'L2_length', 'L3_height', 'L4_width', 'L5_weight']\n",
        "    score = categorize_solution(solution_set)\n",
        "    #print(\"Categorized Result:\", categorized_result)  # Output: \"Good\"\n",
        "    #print(\"Score:\", score)  # Output: The total sum of numbers\n",
        "    score_init = categorize_solution(df_res_init.columns)\n",
        "\n",
        "\n",
        "    privacy_indicator_value = score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ##################################################--------------------Initial vs Best Solution and Optimize BTN and METRIC-------------------#######################################\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "      # Display the initial solution\n",
        "      st.write(\"Initial Solution:\", initial_solution)\n",
        "      #st.write(\"Classification score AUROC:\", '74.5')\n",
        "\n",
        "    if st.sidebar.button(\"Start Optimization\"):\n",
        "      with col2:\n",
        "        # Inside the if condition, display the optimization results\n",
        "        st.write(\"Best Solution:\", solution_set)\n",
        "\n",
        "\n",
        "        #st.write(\"Suppressed Rows:\", suprression_value)\n",
        "        #st.write(\"Best solution AUROC\", accuracy_value)\n",
        "        #st.write(\"Optimized dataset vs. Original dataset\")\n",
        "\n",
        "      st.subheader(\"Comparing Datasets before and after Anonymization\")\n",
        "      tab1, tab2 = st.tabs([\"Original Dataset\", \"Initial Random Dataset\"])\n",
        "      with tab1:\n",
        "            st.markdown(\"**Anonymized Dataset vs Original Dataset**\")\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "            with col1:\n",
        "                st.metric(\n",
        "                    label=\"Percentage of suppressed datapoints\",\n",
        "                    value=str(suprression_value) + \"%\",  # Format as percentage with 2 decimal points\n",
        "                    delta=str(round(suprression_value - 40, 2)) + \"%\"\n",
        "                )\n",
        "\n",
        "            with col2:\n",
        "                st.metric(\n",
        "                    label=\"Classification score (AUROC)\",\n",
        "                    value=accuracy_value,\n",
        "                    delta=round(accuracy_value - 0.77, 3)\n",
        "                )\n",
        "\n",
        "            with col3:\n",
        "                # Define the privacy value with the appropriate emoji\n",
        "                privacy_value_with_emoji = \"😊\" if privacy_indicator_value <= 5 else (\"😐\" if 6 <= privacy_indicator_value <= 15 else \"😔\")\n",
        "\n",
        "                # Concatenate the privacy value and emoji with a space\n",
        "                privacy_info = f\"{privacy_value_with_emoji}\"\n",
        "\n",
        "                # Display the metric with the privacy info\n",
        "                st.metric(\n",
        "                    label=\"Data Privacy\",\n",
        "                    value=privacy_info,\n",
        "                    delta=privacy_indicator_value - 22  # You can set delta to None if you don't need it\n",
        "                )\n",
        "                with st.popover(\"💡\"):\n",
        "                    st.markdown(\"The higher the data privacy indicator value the greater the risk of data exposure as the data is more granular and less generalized. It ranges from 4 to 22 depending on the sum of generalization levels of all features in the solution set.\")\n",
        "\n",
        "\n",
        "      with tab2:\n",
        "            st.markdown(\"**Anonymized Dataset vs. Initial Random Dataset**\")\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "            with col1:\n",
        "                st.metric(\n",
        "                    label=\"Percentage of suppressed datapoints\",\n",
        "                    value=str(suprression_value) + \"%\",\n",
        "                    delta=str(round(suprression_value - initial_suppression, 2)) + \"%\"\n",
        "                )\n",
        "\n",
        "            with col2:\n",
        "                st.metric(\n",
        "                    label=\"Classification score (AUROC)\",\n",
        "                    value=accuracy_value,\n",
        "                    delta=round(accuracy_value - 0.745, 3)\n",
        "                )\n",
        "\n",
        "            with col3:\n",
        "                # Define the privacy value with the appropriate emoji\n",
        "                privacy_value_with_emoji = \"😊\" if privacy_indicator_value <= 5 else (\"😐\" if 6 <= privacy_indicator_value <= 15 else \"😔\")\n",
        "\n",
        "                # Concatenate the privacy value and emoji with a space\n",
        "                privacy_info = f\"{privacy_value_with_emoji} \"\n",
        "\n",
        "                # Display the metric with the privacy info\n",
        "                st.metric(\n",
        "                    label=\"Privacy Indicator\",\n",
        "                    value=privacy_info,\n",
        "                    delta=privacy_indicator_value - score_init  # You can set delta to None if you don't need it\n",
        "                )\n",
        "                with st.popover(\"💡\"):\n",
        "                    st.markdown(\"The higher the data privacy indicator value the greater the risk of data exposure as the data is more granular and less generalized. It ranges from 4 to 22 depending on the sum of generalization levels of all features in the solution set.\")\n",
        "    #col1, col2, col3 = st.sidebar.columns(3)\n",
        "\n",
        "    ##################################################--------------------Display distribution imbalance after anonymization-------------------#######################################\n",
        "\n",
        "      subset_df = df_org_mimic[solution_set]\n",
        "      # Add the 'death_365_days' column from df_org_mimic to the subset_df\n",
        "      subset_df['death_365_days'] = df_org_mimic['death_365_days']\n",
        "      # Print the size of the DataFrame\n",
        "      print(\"Size of subset_df:\", subset_df.shape)\n",
        "      # Group the dataset by the quasi-identifiers\n",
        "      grouped = subset_df.groupby(solution_set)\n",
        "      suppressed_indices = []\n",
        "\n",
        "      # Identify groups with less than k rows and mark for suppression\n",
        "      for group_name, group in grouped:\n",
        "          if len(group) < k:\n",
        "              suppressed_indices.extend(group.index)\n",
        "\n",
        "          # Drop suppressed rows\n",
        "      subset_df_anon = subset_df.drop(suppressed_indices)\n",
        "      print(\"Size of subset_df_anon:\", subset_df_anon.shape)\n",
        "\n",
        "      # Restore the original index\n",
        "      subset_df_anon = subset_df_anon.reset_index(drop=True)\n",
        "      print(\"Size of subset_df_anon after reset index:\", subset_df_anon.shape)\n",
        "\n",
        "      display_datasets(df_res_init, df_org, subset_df_anon)\n",
        "      display_datasets_with_distribution(df_org_mimic, subset_df_anon)\n",
        "\n",
        "\n",
        "######################################START OF ADULT CENSUS DATASET OVERVIEW######################################\n",
        "def adult_census_datset_overview():\n",
        "\n",
        "    def calculate_suppression_fraction(df, k, test_solution):\n",
        "        # Group the dataset by the quasi-identifiers\n",
        "        grouped = df.groupby(test_solution)\n",
        "        suppressed_indices = []\n",
        "\n",
        "        # Identify groups with less than k rows and mark for suppression\n",
        "        for group_name, group in grouped:\n",
        "            if len(group) < k:\n",
        "                suppressed_indices.extend(group.index)\n",
        "\n",
        "        # Drop suppressed rows\n",
        "        df_k = df.drop(suppressed_indices)\n",
        "\n",
        "        # Restore the original index\n",
        "        df_index = df_k.index\n",
        "        df_k = df_k.reset_index(drop=True)\n",
        "\n",
        "        # Calculate suppression fraction\n",
        "        suppressed_rows = len(suppressed_indices)\n",
        "        total_rows = len(df)\n",
        "        initial_suppression = suppressed_rows / total_rows\n",
        "        initial_suppression = round(initial_suppression * 100, 2)\n",
        "\n",
        "        return initial_suppression\n",
        "\n",
        "\n",
        "    def get_accuracy(df1, k, max_suppressed_fraction): # Takes experimental results df as input and returns auroc, solution set and suppression %\n",
        "        # Filter DataFrame based on k and max_supp values\n",
        "        filtered_df = df1[(df1['K'] == k) & (df1['max suppression %'] == max_suppressed_fraction)]\n",
        "\n",
        "        # Check if any rows match the criteria\n",
        "        if not filtered_df.empty:\n",
        "            # Retrieve accuracy value (assuming there's only one match)\n",
        "            accuracy_value = filtered_df['median auroc'].iloc[0]\n",
        "            suprression_value = filtered_df['suppression in %'].iloc[0]\n",
        "            suprression_value = suprression_value * 100\n",
        "            solution_set = filtered_df['solution set SA'].iloc[0]\n",
        "            solution_set = [item.strip(\"'\") for item in solution_set.split(\",\")]\n",
        "            # Clean up the solution set\n",
        "            solution_set = [col.strip().replace(\"'\", \"\").replace('\"', '') for col in solution_set]\n",
        "\n",
        "            return accuracy_value, suprression_value, solution_set\n",
        "        else:\n",
        "            return None  # Return None if no matching rows found\n",
        "\n",
        "\n",
        "    def display_datasets(df_res_init, df_org, subset_df):\n",
        "       st.header(\"Display Datasets\")\n",
        "       # Create columns to display datasets side by side\n",
        "       selected_datasets = st.multiselect(\"Select datasets to display:\", [\"Original Dataset\", \"Initial Dataset\", \"Optimized Dataset\"], default=[\"Original Dataset\"] )\n",
        "       # Calculate the number of columns needed based on the number of selected datasets\n",
        "       num_columns = len(selected_datasets)\n",
        "       # Create columns to display datasets side by side\n",
        "       cols = st.columns(num_columns)\n",
        "\n",
        "\n",
        "       for i, dataset in enumerate(selected_datasets):\n",
        "           if dataset == \"Original Dataset\":\n",
        "               with cols[i]:\n",
        "                   st.write(\"### Original Dataset\")\n",
        "                   st.dataframe(df_org)\n",
        "           elif dataset == \"Initial Dataset\":\n",
        "               with cols[i]:\n",
        "                   st.write(\"### Initial Dataset\")\n",
        "                   st.dataframe(df_res_init_adult)\n",
        "           elif dataset == \"Optimized Dataset\":\n",
        "               with cols[i]:\n",
        "                   st.write(\"### Optimized Dataset\")\n",
        "                   st.dataframe(subset_df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def display_datasets_with_distribution(original_dataset, anon_dataset):\n",
        "          st.subheader(\"Display change in data distribution after anonymization:\")\n",
        "          tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([\"Age\", \"Sex\", \"Education\", \"Occupation\", \"Marital status\", \"Death within 360 days\"])\n",
        "\n",
        "          with tab1:\n",
        "              # Filter columns containing the word \"age\"\n",
        "              age_column = [col for col in anon_dataset.columns if 'age' in col.lower()]\n",
        "              print(\"Age column?\", age_column)\n",
        "\n",
        "              fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "              sns.histplot(original_dataset[\"L7_age\"], kde=True, color=\"blue\", label=\"Original Dataset\", ax=axes[0])\n",
        "              axes[0].set_xlabel(\"Age\")\n",
        "              axes[0].set_ylabel(\"Frequency\")\n",
        "              axes[0].set_title(\"Distribution of Age (Original Dataset)\")\n",
        "              axes[0].tick_params(axis='x', labelrotation=90)\n",
        "\n",
        "              sns.histplot(anon_dataset[age_column[0]], kde=True, color=\"orange\", label=\"Anonymized Dataset\", ax=axes[1])\n",
        "              axes[1].set_xlabel(\"Age\")\n",
        "              axes[1].set_ylabel(\"Frequency\")\n",
        "              axes[1].set_title(\"Distribution of Age (Anonymized Dataset)\")\n",
        "              axes[1].tick_params(axis='x', labelrotation=90)\n",
        "\n",
        "              plt.tight_layout()\n",
        "              st.pyplot(fig)\n",
        "\n",
        "          with tab2:\n",
        "              # Filter columns containing the word \"Sex\"\n",
        "              sex_column = [col for col in anon_dataset.columns if 'sex' in col.lower()]\n",
        "\n",
        "              fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "              sns.histplot(original_dataset[\"sex\"], kde=True, color=\"blue\", label=\"Original Dataset\", ax=axes[0])\n",
        "              axes[0].set_xlabel(\"Sex\")\n",
        "              axes[0].set_ylabel(\"Frequency\")\n",
        "              axes[0].set_title(\"Distribution of sex (Original Dataset)\")\n",
        "              #axes[0].tick_params(axis='x', labelrotation=90)\n",
        "\n",
        "              sns.histplot(anon_dataset[sex_column[0]], kde=True, color=\"orange\", label=\"Anonymized Dataset\", ax=axes[1])\n",
        "              axes[1].set_xlabel(\"Sex\")\n",
        "              axes[1].set_ylabel(\"Frequency\")\n",
        "              axes[1].set_title(\"Distribution of Sex (Anonymized Dataset)\")\n",
        "              #axes[1].tick_params(axis='x', labelrotation=90)\n",
        "\n",
        "              plt.tight_layout()\n",
        "              st.pyplot(fig)\n",
        "\n",
        "          with tab3:\n",
        "              # Filter columns containing the word \"Education\"\n",
        "              education_column = [col for col in anon_dataset.columns if 'education' in col.lower()]\n",
        "              #print(\"Age column?\", education_column)\n",
        "\n",
        "              fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "              sns.histplot(original_dataset[\"L5_education\"], kde=True, color=\"blue\", label=\"Original Dataset\", ax=axes[0])\n",
        "              axes[0].set_xlabel(\"Education\")\n",
        "              axes[0].set_ylabel(\"Frequency\")\n",
        "              axes[0].set_title(\"Distribution of Education (Original Dataset)\")\n",
        "              axes[0].tick_params(axis='x', labelrotation=90)\n",
        "\n",
        "              sns.histplot(anon_dataset[education_column[0]], kde=True, color=\"orange\", label=\"Anonymized Dataset\", ax=axes[1])\n",
        "              axes[1].set_xlabel(\"L3_education\")\n",
        "              axes[1].set_ylabel(\"Frequency\")\n",
        "              axes[1].set_title(\"Distribution of Education (Anonymized Dataset)\")\n",
        "              axes[1].tick_params(axis='x', labelrotation=90)\n",
        "\n",
        "              plt.tight_layout()\n",
        "              st.pyplot(fig)\n",
        "\n",
        "          with tab4:\n",
        "              # Filter columns containing the word \"Occupation\"\n",
        "              occupation_column = [col for col in anon_dataset.columns if 'occupation' in col.lower()]\n",
        "              #print(\"Age column?\", occupation_column)\n",
        "\n",
        "              fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "              sns.histplot(original_dataset[\"L3_occupation\"], kde=True, color=\"blue\", label=\"Original Dataset\", ax=axes[0])\n",
        "              axes[0].set_xlabel(\"Occupation\")\n",
        "              axes[0].set_ylabel(\"Frequency\")\n",
        "              axes[0].set_title(\"Distribution of Occupation (Original Dataset)\")\n",
        "              axes[0].tick_params(axis='x', labelrotation=90)\n",
        "\n",
        "              sns.histplot(anon_dataset[occupation_column[0]], kde=True, color=\"orange\", label=\"Anonymized Dataset\", ax=axes[1])\n",
        "              axes[1].set_xlabel(\"Occupation\")\n",
        "              axes[1].set_ylabel(\"Frequency\")\n",
        "              axes[1].set_title(\"Distribution of Occupation (Anonymized Dataset)\")\n",
        "              axes[1].tick_params(axis='x', labelrotation=90)\n",
        "\n",
        "              plt.tight_layout()\n",
        "              st.pyplot(fig)\n",
        "\n",
        "          with tab5:\n",
        "              # Filter columns containing the word \"Marital status\"\n",
        "              marital_status_column = [col for col in anon_dataset.columns if 'marital_status' in col.lower()]\n",
        "\n",
        "              fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "              sns.histplot(original_dataset[\"L3_marital_status\"], kde=True, color=\"blue\", label=\"Original Dataset\", ax=axes[0])\n",
        "              axes[0].set_xlabel(\"Marital Status\")\n",
        "              axes[0].set_ylabel(\"Frequency\")\n",
        "              axes[0].set_title(\"Distribution of Marital status (Original Dataset)\")\n",
        "              axes[0].tick_params(axis='x', labelrotation=90)\n",
        "\n",
        "              sns.histplot(anon_dataset[marital_status_column[0]], kde=True, color=\"orange\", label=\"Anonymized Dataset\", ax=axes[1])\n",
        "              axes[1].set_xlabel(\"Marital status\")\n",
        "              axes[1].set_ylabel(\"Frequency\")\n",
        "              axes[1].set_title(\"Distribution of Marital status (Anonymized Dataset)\")\n",
        "              axes[1].tick_params(axis='x', labelrotation=90)\n",
        "\n",
        "              plt.tight_layout()\n",
        "              st.pyplot(fig)\n",
        "\n",
        "          with tab6:\n",
        "              # Filter columns containing the word \"Salary\"\n",
        "              salary_class_column = [col for col in anon_dataset.columns if 'salary-class' in col.lower()]\n",
        "\n",
        "              fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "              sns.histplot(original_dataset[\"salary-class\"], kde=True, color=\"blue\", label=\"Original Dataset\", ax=axes[0])\n",
        "              axes[0].set_xlabel(\"Salary\")\n",
        "              axes[0].set_ylabel(\"Frequency\")\n",
        "              axes[0].set_title(\"Distribution of Salary (Original Dataset)\")\n",
        "\n",
        "              sns.histplot(anon_dataset[salary_class_column[0]], kde=True, color=\"orange\", label=\"Anonymized Dataset\", ax=axes[1])\n",
        "              axes[1].set_xlabel(\"Salary\")\n",
        "              axes[1].set_ylabel(\"Frequency\")\n",
        "              axes[1].set_title(\"Distribution of Salary (Anonymized Dataset)\")\n",
        "              #axes[1].tick_params(axis='x', labelrotation=90)\n",
        "\n",
        "              plt.tight_layout()\n",
        "              st.pyplot(fig)\n",
        "\n",
        "\n",
        "\n",
        "    # Define the Streamlit app title\n",
        "    st.header(\"Simulated Annealing Optimization - Adult Census\")\n",
        "    st.markdown(\"The Adult Census dataset, contains demographic information about individuals, such as age, education, marital status, occupation, and income level. It is commonly used for predictive modeling tasks, particularly for binary classification problems to predict whether an individual earns more than $50,000 per year based on their demographic attributes. \")\n",
        "    #st.markdown(''' :red[Streamlit] :orange[can] :green[write] :blue[text] :violet[in] :gray[pretty] :rainbow[colors].''')\n",
        "    st.markdown(''':green[Predictors:] age, sex, race, education, occupation, workclass, marital_status, native country ''')\n",
        "    # Quasi Identifiers\n",
        "    #st.markdown(\"<span style='color:green'>**Quasi Identifiers:**</span>\", unsafe_allow_html=True)\n",
        "    st.markdown( ''':green[Quasi identifiers:] age, sex, race, education, occupation, workclass, marital_status, native country ''')\n",
        "\n",
        "    ##################################################--------------------SIDEBAR-------------------#######################################\n",
        "    # Create Streamlit widgets for user input\n",
        "    st.sidebar.header(\"User Settings\")\n",
        "    k = st.sidebar.slider(\"k-Anonymity Threshold\", min_value=2, max_value=10, value=2, step=1)\n",
        "\n",
        "    max_suppressed_fraction = st.sidebar.slider(\"Maximum suppression\", min_value=10, max_value=30, value=20, step=10)\n",
        "\n",
        "    accuracy_value, suprression_value, solution_set = get_accuracy(df_exp_adult, k, max_suppressed_fraction)\n",
        "\n",
        "    initial_solution = ['sex', 'L6_age', 'L2_race', 'L3_education', 'L3_occupation', 'L3_workclass', 'L2_marital_status', 'L1_native_country']\n",
        "    #k_init = st.sidebar.slider(\"k-Anonymity on initial solution\", min_value=2, max_value=10, value=2, step=1)\n",
        "    initial_suppression = calculate_suppression_fraction(df_org_adult, k, initial_solution) # change to percentage to have suppression percentage of initial random solution when k is applied\n",
        "\n",
        "    ##################################################--------------------Privacy Indicator (Ampel)-------------------#######################################\n",
        "    def categorize_solution(solution_set):\n",
        "        # Extract numbers from column names\n",
        "        numbers = [int(''.join(filter(str.isdigit, col))) for col in solution_set if any(char.isdigit() for char in col)]\n",
        "\n",
        "        # Sum up the numbers\n",
        "        total = sum(numbers)\n",
        "\n",
        "        # Normalize the score\n",
        "        #normalized_score = (total - min(numbers)) / (max(numbers) - min(numbers))\n",
        "\n",
        "       # Reverse the score\n",
        "        #reversed_score = 1 - normalized_score\n",
        "\n",
        "      # Categorize based on the reversed normalized score\n",
        "        if 7 <= total <= 12:\n",
        "            return total\n",
        "        elif 13 <= total <= 19:\n",
        "            return total\n",
        "        else:\n",
        "            return total\n",
        "\n",
        "    # Example usage:\n",
        "    score = categorize_solution(solution_set)\n",
        "    #print(\"Categorized Result:\", categorized_result)  # Output: \"Good\"\n",
        "    #print(\"Score:\", score)  # Output: The total sum of numbers\n",
        "    score_init = categorize_solution(df_res_init_adult.columns)\n",
        "\n",
        "\n",
        "    privacy_indicator_value = score\n",
        "\n",
        "\n",
        "     ##################################################--------------------Initial vs Best Solution and Optimize BTN and METRIC-------------------#######################################\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "      # Display the initial solution\n",
        "      st.write(\"Initial Solution:\", initial_solution)\n",
        "      #st.write(\"Classification score AUROC:\", '74.5')\n",
        "\n",
        "    if st.sidebar.button(\"Start Optimization\"):\n",
        "      with col2:\n",
        "        # Inside the if condition, display the optimization results\n",
        "        st.write(\"Best Solution:\", solution_set)\n",
        "\n",
        "\n",
        "        #st.write(\"Suppressed Rows:\", suprression_value)\n",
        "        #st.write(\"Best solution AUROC\", accuracy_value)\n",
        "        #st.write(\"Optimized dataset vs. Original dataset\")\n",
        "\n",
        "      st.subheader(\"Comparing Datasets before and after Anonymization\")\n",
        "      tab1, tab2 = st.tabs([\"Original Dataset\", \"Initial Random Dataset\"])\n",
        "      with tab1:\n",
        "            st.markdown(\"**Anonymized Dataset vs Original Dataset**\")\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "            with col1:\n",
        "                st.metric(\n",
        "                    label=\"Percentage of suppressed datapoints\",\n",
        "                    value=str(suprression_value) + \"%\",  # Format as percentage with 2 decimal points\n",
        "                    delta=str(round(suprression_value - 50, 2)) + \"%\"\n",
        "                )\n",
        "\n",
        "            with col2:\n",
        "                st.metric(\n",
        "                    label=\"Classification score (AUROC)\",\n",
        "                    value=accuracy_value,\n",
        "                    delta=round(accuracy_value - 0.77, 3)\n",
        "                )\n",
        "\n",
        "            with col3:\n",
        "                # Define the privacy value with the appropriate emoji\n",
        "                privacy_value_with_emoji = \"😊\" if privacy_indicator_value <= 12 else (\"😐\" if 13 <= privacy_indicator_value <= 19 else \"😔\")\n",
        "\n",
        "                # Concatenate the privacy value and emoji with a space\n",
        "                privacy_info = f\"{privacy_value_with_emoji} \"\n",
        "\n",
        "                # Display the metric with the privacy info\n",
        "                st.metric(\n",
        "                    label=\"Privacy Indicator\",\n",
        "                    value=privacy_info,\n",
        "                    delta=privacy_indicator_value - 22  # You can set delta to None if you don't need it\n",
        "                )\n",
        "                with st.popover(\"💡\"):\n",
        "                    st.markdown(\"The higher the data privacy indicator value the greater the risk of data exposure as the data is more granular and less generalized. It ranges from 7 to 26 depending on the sum of generalization levels of all features in the solution set.\")\n",
        "\n",
        "\n",
        "      with tab2:\n",
        "            st.markdown(\"**Anonymized Dataset vs. Initial Random Dataset**\")\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "            with col1:\n",
        "                st.metric(\n",
        "                    label=\"Percentage of suppressed datapoints\",\n",
        "                    value=str(suprression_value) + \"%\",\n",
        "                    delta=str(round(suprression_value - initial_suppression, 2)) + \"%\"\n",
        "                )\n",
        "\n",
        "            with col2:\n",
        "                st.metric(\n",
        "                    label=\"Classification score (AUROC)\",\n",
        "                    value=accuracy_value,\n",
        "                    delta=round(accuracy_value - 0.732, 3)\n",
        "                )\n",
        "\n",
        "            with col3:\n",
        "                # Define the privacy value with the appropriate emoji\n",
        "                privacy_value_with_emoji = \"😊\" if privacy_indicator_value <= 12 else (\"😐\" if 13 <= privacy_indicator_value <= 19 else \"😔\")\n",
        "\n",
        "                # Concatenate the privacy value and emoji with a space\n",
        "                privacy_info = f\"{privacy_value_with_emoji} \"\n",
        "\n",
        "                # Display the metric with the privacy info\n",
        "                st.metric(\n",
        "                    label=\"Privacy Indicator\",\n",
        "                    value=privacy_info,\n",
        "                    delta=privacy_indicator_value - score_init  # You can set delta to None if you don't need it\n",
        "                )\n",
        "                with st.popover(\"💡\"):\n",
        "                    st.markdown(\"The higher the data privacy indicator value the greater the risk of data exposure as the data is more granular and less generalized. It ranges from 7 to 26 depending on the sum of generalization levels of all features in the solution set.\")\n",
        "\n",
        "   ##################################################--------------------Display distribution imbalance after anonymization-------------------#######################################\n",
        "\n",
        "      subset_df = df_org_adult[solution_set]\n",
        "      # Add the 'salary-class' column from df_org_adult to the subset_df\n",
        "      subset_df['salary-class'] = df_org_adult['salary-class']\n",
        "      # Print the size of the DataFrame\n",
        "      print(\"Size of subset_df:\", subset_df.shape)\n",
        "      # Group the dataset by the quasi-identifiers\n",
        "      grouped = subset_df.groupby(solution_set)\n",
        "      suppressed_indices = []\n",
        "\n",
        "      # Identify groups with less than k rows and mark for suppression\n",
        "      for group_name, group in grouped:\n",
        "          if len(group) < k:\n",
        "              suppressed_indices.extend(group.index)\n",
        "\n",
        "          # Drop suppressed rows\n",
        "      subset_df_anon = subset_df.drop(suppressed_indices)\n",
        "      print(\"Size of subset_df_anon:\", subset_df_anon.shape)\n",
        "\n",
        "      # Restore the original index\n",
        "      subset_df_anon = subset_df_anon.reset_index(drop=True)\n",
        "      print(\"Size of subset_df_anon after reset index:\", subset_df_anon.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #st.subheader(\"Original Dataset\")\n",
        "    #st.dataframe(df_org)\n",
        "\n",
        "      # Function to display datasets\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      display_datasets(df_res_init_adult, df_org_adult, subset_df_anon)\n",
        "      display_datasets_with_distribution(df_org_adult, subset_df_anon)\n",
        "\n",
        "\n",
        "\n",
        "#####################################################HOME PAGE################################################\n",
        "# Define function for home page\n",
        "def home():\n",
        "    st.title(\"PrivacyShade Demo App\")\n",
        "    st.subheader(\"Welcome to the Utility Preserving Data Anonymization Demo App\")\n",
        "    st.write(\"*The idea is based on **Simulated Annealing**, an optimization technique inspired by the metallurgical annealing process. It is essential in solving the challenge of searching hierarchical data generalizations. It begins by exploring various configurations, adjusting them iteratively while probabilistically accepting worse solutions early to thoroughly explore the solution space. This ensures that both your privacy requirements, such as **k-anonymity** constraints, and your goal of achieving **high classification scores** are effectively balanced. As the algorithm progresses, it refines its approach, aiming to find the optimal solution where privacy is preserved without compromising data utility.*\")\n",
        "    #st.write(\"Select a dataset to explore:\")\n",
        "    selected_datasets = st.selectbox(\"Select a dataset to explore:\", [\"MIMIC III Dataset\", \"Adult Income Dataset\"])\n",
        "    if selected_datasets == \"MIMIC III Dataset\":\n",
        "          st.markdown(\"**:green[Dataset description:]** 360-day mortality prediction among intensive care unit (ICU) stroke inpatients\")\n",
        "          #st.markdown(''' :red[Streamlit] :orange[can] :green[write] :blue[text] :violet[in] :gray[pretty] :rainbow[colors].''')\n",
        "          st.markdown('''**:green[Predictors:]** age, length of stay/h, admission type, gender, stroke type, marital status, diseases, ethnicity, infarct type, anion gap, abp diastolic, abp systolic, bicarbonate, calcium, chloride, creatinine, gcs, glucose, heart rate, hemoglobin,  oasis, wbc, platelet count, potassium, respiratory rate, sodium ''')\n",
        "          # Quasi Identifiers\n",
        "          #st.markdown(\"<span style='color:green'>**Quasi Identifiers:**</span>\", unsafe_allow_html=True)\n",
        "          st.markdown( ''' **:green[Quasi identifiers:]** age, length of stay/h, admission type, gender, stroke type, marital status, diseases, ethnicity ''')\n",
        "          st.markdown(\" **:green[Dataset size:]** 2655 rows and 27 columns\")\n",
        "          st.subheader(\"Dataset Overview\")\n",
        "          selected_columns = ['L7_age', 'gender', 'L3_Ethnicity', 'marital_status', 'infarct_type',\n",
        "          'anion_gap', 'abp_diastolic', 'abp_systolic', 'bicarbonate', 'calcium',\n",
        "          'chloride', 'creatinine', 'gcs', 'glucose', 'heart_rate', 'hemoglobin',\n",
        "          'oasis', 'L7_los_hours', 'platelet_count', 'potassium',\n",
        "          'repiratory_rate', 'sodium', 'wbc', 'stroke_type', 'L2_Admission_Type', 'diseases', 'death_365_days']\n",
        "          st.dataframe(df_org_mimic[selected_columns])\n",
        "          st.subheader(\"MIMIC III Generalization Hierarchies\")\n",
        "          tab1, tab2, tab3, tab4 = st.tabs([\"Age\", \"Ethnicity\", \"Diseases\", \"Admission Type\"])\n",
        "          with tab1:\n",
        "            #st.header(\"Age\")\n",
        "            st.image(\"https://raw.githubusercontent.com/desstaw/PrivacyPreservingTechniques/main/SA%20Demo%20App/age_mimic.png\")\n",
        "          with tab2:\n",
        "            #st.header(\"Admission Type\")\n",
        "            st.image(\"https://raw.githubusercontent.com/desstaw/PrivacyPreservingTechniques/main/SA%20Demo%20App/diseases_mimic.png\")\n",
        "          with tab3:\n",
        "            #st.header(\"Ethnicity\")\n",
        "            st.image(\"https://raw.githubusercontent.com/desstaw/PrivacyPreservingTechniques/main/SA%20Demo%20App/ethnicity_mimic.png\")\n",
        "          with tab4:\n",
        "            st.image(\"https://raw.githubusercontent.com/desstaw/PrivacyPreservingTechniques/main/SA%20Demo%20App/admissin_mimic.png\")\n",
        "\n",
        "    if selected_datasets == \"Adult Income Dataset\":\n",
        "          st.markdown(\"**:green[Dataset description:]** The Adult Census dataset, contains demographic information about individuals, such as age, education, marital status, occupation, and income level. It is commonly used for predictive modeling tasks, particularly for binary classification problems to predict whether an individual earns more than $50,000 per year based on their demographic attributes.\")\n",
        "          #st.markdown(''' :red[Streamlit] :orange[can] :green[write] :blue[text] :violet[in] :gray[pretty] :rainbow[colors].''')\n",
        "          st.markdown('''**:green[Predictors:]** age, sex, race, education, occupation, workclass, marital_status, native country ''')\n",
        "          # Quasi Identifiers\n",
        "          #st.markdown(\"<span style='color:green'>**Quasi Identifiers:**</span>\", unsafe_allow_html=True)\n",
        "          st.markdown( ''' **:green[Quasi identifiers:]** age, sex, race, education, occupation, workclass, marital_status, native country ''')\n",
        "          st.markdown(\" **:green[Dataset size:]** 32,561 rows and 9 columns\")\n",
        "          st.subheader(\"Dataset Overview\")\n",
        "\n",
        "          st.dataframe(df_org_adult)\n",
        "          st.subheader(\"Adult Census Generalization Hierarchies\")\n",
        "          tab1, tab2, tab3, = st.tabs([\"Education\", \"Occupation\", \"Marital Status\"])\n",
        "          with tab1:\n",
        "            #st.header(\"Age\")\n",
        "            st.image(\"https://raw.githubusercontent.com/desstaw/PrivacyPreservingTechniques/main/SA%20Demo%20App/education_adult.png\")\n",
        "          with tab2:\n",
        "            #st.header(\"Education\")\n",
        "            st.image(\"https://raw.githubusercontent.com/desstaw/PrivacyPreservingTechniques/main/SA%20Demo%20App/occupation_adult.png\")\n",
        "          with tab3:\n",
        "            #st.header(\"Occupation\")\n",
        "            st.image(\"https://raw.githubusercontent.com/desstaw/PrivacyPreservingTechniques/main/SA%20Demo%20App/marital_status_adult.png\")\n",
        "\n",
        "\n",
        "\n",
        "# Define function for MIMIC III Dataset overview\n",
        "def mimic_overview():\n",
        "    mimic_dataset_overview()\n",
        "\n",
        "# Define function for Adult Census Dataset overview\n",
        "def adult_census_overview():\n",
        "    st.title(\"Overview of Adult Census Dataset\")\n",
        "    # Add content for Adult Census Dataset overview\n",
        "    adult_census_datset_overview()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Main function to run the app\n",
        "def main():\n",
        "    # Create sidebar navigation\n",
        "    page = st.sidebar.selectbox(\"Select a page\", [\"Home\", \"Optimizing MIMIC III Dataset\", \"Optimizing Adult Census Dataset\"])\n",
        "\n",
        "    # Display different pages based on selection\n",
        "    if page == \"Home\":\n",
        "        home()\n",
        "    elif page == \"Optimizing MIMIC III Dataset\":\n",
        "        mimic_overview()\n",
        "    elif page == \"Optimizing Adult Census Dataset\":\n",
        "        adult_census_overview()\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCFDf3WHFTkb",
        "outputId": "efb30d8e-65b8-4dd6-ffb6-25328ca45303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.33.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.0)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.11.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.1.6)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXoaAY-EiMbr",
        "outputId": "c393b91a-84a3-415d-d7e0-24aa10ecf721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 1.299s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 2 \u001b[93mmoderate\u001b[0m severity vulnerabilities\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmIXfGDYIaht",
        "outputId": "2a6b2000-57f1-46b3-90e6-54eebeb9b7d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.232.154.6\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Start Streamlit app on a specific port\n",
        "!streamlit run app.py &>/content/logs.txt & curl ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pUprsVXiT3s",
        "outputId": "33b987f6-dfb4-4332-f91b-863b196182bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 5.883s\n",
            "your url is: https://all-doodles-read.loca.lt\n",
            "/root/.npm/_npx/3304/lib/node_modules/localtunnel/bin/lt.js:81\n",
            "    throw err;\n",
            "    ^\n",
            "\n",
            "Error: connection refused: localtunnel.me:42147 (check your firewall settings)\n",
            "    at Socket.<anonymous> (/root/.npm/_npx/3304/lib/node_modules/\u001b[4mlocaltunnel\u001b[24m/lib/TunnelCluster.js:52:11)\n",
            "\u001b[90m    at Socket.emit (events.js:315:20)\u001b[39m\n",
            "\u001b[90m    at emitErrorNT (internal/streams/destroy.js:106:8)\u001b[39m\n",
            "\u001b[90m    at emitErrorCloseNT (internal/streams/destroy.js:74:3)\u001b[39m\n",
            "\u001b[90m    at processTicksAndRejections (internal/process/task_queues.js:80:21)\u001b[39m\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}